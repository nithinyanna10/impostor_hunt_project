{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14313e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                             text_1  \\\n",
      "0   0  The VIRSA (Visible Infrared Survey Telescope A...   \n",
      "1   1  China\\nThe goal of this project involves achie...   \n",
      "2   2  Scientists can learn about how galaxies form a...   \n",
      "3   3  China\\nThe study suggests that multiple star s...   \n",
      "4   4  Dinosaur Rex was excited about his new toy set...   \n",
      "\n",
      "                                              text_2  real  \n",
      "0  The China relay network has released a signifi...     1  \n",
      "1  The project aims to achieve an accuracy level ...     2  \n",
      "2  Dinosaur eggshells offer clues about what dino...     1  \n",
      "3  The importance for understanding how stars evo...     2  \n",
      "4  Analyzing how fast stars rotate within a galax...     2  \n",
      "Loaded 95 article pairs.\n"
     ]
    }
   ],
   "source": [
    "from src.data_loader import load_train_data\n",
    "\n",
    "# Use the correct relative path since the notebook is in the 'notebooks' folder\n",
    "df = load_train_data(\"../data\", verbose=True)\n",
    "print(f\"Loaded {len(df)} article pairs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87defbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  cosine_similarity  len_text_1  len_text_2  len_diff  \\\n",
      "0   0           0.599699        2196        2018       178   \n",
      "1   1           0.526418        3124         936      2188   \n",
      "2   2           0.214112        1139         801       338   \n",
      "3   3           0.543035        1774        1869        95   \n",
      "4   4          -0.040034         195         871       676   \n",
      "\n",
      "   t1_flesch_reading_ease  t1_gunning_fog  t1_smog_index  \\\n",
      "0               -4.937217       25.991505      21.883775   \n",
      "1               -3.233476       28.407473      21.883775   \n",
      "2                0.219231       25.343590      20.967145   \n",
      "3               23.320625       18.873755      16.526678   \n",
      "4               68.431667       10.415686      11.208143   \n",
      "\n",
      "   t1_automated_readability_index  t2_flesch_reading_ease  ...  t2_smog_index  \\\n",
      "0                       24.176824               16.921750  ...      17.805411   \n",
      "1                       31.391265               19.810833  ...      17.122413   \n",
      "2                       27.129811               18.196183  ...      19.287187   \n",
      "3                       21.960523               -1.330588  ...      21.828452   \n",
      "4                        6.678431               11.415000  ...      19.784474   \n",
      "\n",
      "   t2_automated_readability_index  t1_num_entities  t1_num_persons  \\\n",
      "0                       20.386655               19               1   \n",
      "1                       17.323650               10               0   \n",
      "2                       24.746027                3               0   \n",
      "3                       25.691461               15               2   \n",
      "4                       22.251220                0               0   \n",
      "\n",
      "   t1_num_orgs  t1_num_dates  t2_num_entities  t2_num_persons  t2_num_orgs  \\\n",
      "0            7             1               11               1            1   \n",
      "1            2             0                5               1            1   \n",
      "2            1             0                7               1            0   \n",
      "3            3             0                4               0            4   \n",
      "4            0             0                2               0            0   \n",
      "\n",
      "   t2_num_dates  \n",
      "0             2  \n",
      "1             0  \n",
      "2             2  \n",
      "3             0  \n",
      "4             0  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "from src.data_loader import load_train_data\n",
    "from src.feature_engineering import extract_features\n",
    "\n",
    "df = load_train_data(\"../data\")\n",
    "features_df = extract_features(df)\n",
    "print(features_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "443b35a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['id'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m os.makedirs(\u001b[33m\"\u001b[39m\u001b[33m../submission\u001b[39m\u001b[33m\"\u001b[39m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Make predictions and save to the submissions directory\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[43mpredict_on_test\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodels/xgboost_model.pkl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../submission/submission_xgb.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m predict_on_test(\u001b[33m\"\u001b[39m\u001b[33mmodels/lightgbm_model.pkl\u001b[39m\u001b[33m\"\u001b[39m, test_df, \u001b[33m\"\u001b[39m\u001b[33m../submission/submission_lgb.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m predict_on_test(\u001b[33m\"\u001b[39m\u001b[33mmodels/logistic_model.pkl\u001b[39m\u001b[33m\"\u001b[39m, test_df, \u001b[33m\"\u001b[39m\u001b[33m../submission/submission_log.csv\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/impostor_hunt_project/notebooks/../src/predict.py:18\u001b[39m, in \u001b[36mpredict_on_test\u001b[39m\u001b[34m(model_path, raw_test_df, output_csv_path)\u001b[39m\n\u001b[32m     16\u001b[39m model = load_model(model_path)\n\u001b[32m     17\u001b[39m features_df = extract_features(raw_test_df)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m X = \u001b[43mfeatures_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mid\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[33m\"\u001b[39m\u001b[33mpredict_proba\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     21\u001b[39m     probs = model.predict_proba(X)[:, \u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/impostor_hunt_project/venv/lib/python3.13/site-packages/pandas/core/frame.py:5588\u001b[39m, in \u001b[36mDataFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   5440\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop\u001b[39m(\n\u001b[32m   5441\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5442\u001b[39m     labels: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5449\u001b[39m     errors: IgnoreRaise = \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5450\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5451\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5452\u001b[39m \u001b[33;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[32m   5453\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5586\u001b[39m \u001b[33;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[32m   5587\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5588\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5589\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5590\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5591\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5592\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5593\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5594\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5595\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5596\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/impostor_hunt_project/venv/lib/python3.13/site-packages/pandas/core/generic.py:4807\u001b[39m, in \u001b[36mNDFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   4805\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes.items():\n\u001b[32m   4806\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4807\u001b[39m         obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4809\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   4810\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_inplace(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/impostor_hunt_project/venv/lib/python3.13/site-packages/pandas/core/generic.py:4849\u001b[39m, in \u001b[36mNDFrame._drop_axis\u001b[39m\u001b[34m(self, labels, axis, level, errors, only_slice)\u001b[39m\n\u001b[32m   4847\u001b[39m         new_axis = axis.drop(labels, level=level, errors=errors)\n\u001b[32m   4848\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4849\u001b[39m         new_axis = \u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4850\u001b[39m     indexer = axis.get_indexer(new_axis)\n\u001b[32m   4852\u001b[39m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[32m   4853\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/impostor_hunt_project/venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:7098\u001b[39m, in \u001b[36mIndex.drop\u001b[39m\u001b[34m(self, labels, errors)\u001b[39m\n\u001b[32m   7096\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m   7097\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors != \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7098\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask].tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in axis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   7099\u001b[39m     indexer = indexer[~mask]\n\u001b[32m   7100\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.delete(indexer)\n",
      "\u001b[31mKeyError\u001b[39m: \"['id'] not found in axis\""
     ]
    }
   ],
   "source": [
    "from src.data_loader import load_train_data\n",
    "from src.feature_engineering import extract_features\n",
    "from src.predict import predict_on_test\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load test data from test.csv\n",
    "test_df = pd.read_csv(\"../data/test.csv\")\n",
    "test_df[\"real\"] = 1  # dummy column if needed by feature pipeline\n",
    "\n",
    "# Extract features\n",
    "features_df = extract_features(test_df)\n",
    "\n",
    "# Ensure the submissions directory exists\n",
    "os.makedirs(\"../submission\", exist_ok=True)\n",
    "\n",
    "# Make predictions and save to the submissions directory\n",
    "predict_on_test(\"models/xgboost_model.pkl\", test_df, \"../submission/submission_xgb.csv\")\n",
    "predict_on_test(\"models/lightgbm_model.pkl\", test_df, \"../submission/submission_lgb.csv\")\n",
    "predict_on_test(\"models/logistic_model.pkl\", test_df, \"../submission/submission_log.csv\")\n",
    "\n",
    "print(\"✅ Predictions saved in the submission directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b987b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Test data saved as test.csv in the data directory.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "test_dir = \"../data/test\"\n",
    "test_files = [f for f in os.listdir(test_dir) if f.endswith(\".txt\")]\n",
    "\n",
    "test_data = []\n",
    "for fname in test_files:\n",
    "    with open(os.path.join(test_dir, fname), \"r\") as f:\n",
    "        text = f.read()\n",
    "        test_data.append({\"id\": fname, \"text\": text})\n",
    "\n",
    "test_df = pd.DataFrame(test_data)\n",
    "test_df[\"real\"] = 1  # dummy column\n",
    "\n",
    "# Save as CSV in the data directory\n",
    "test_df.to_csv(\"../data/test.csv\", index=False)\n",
    "print(\"✅ Test data saved as test.csv in the data directory.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
